# ğŸ¥ Real-Time Post-Surgery Follow-Up Voice Agent

This project implements a **real-time conversational medical voice agent** that performs a post-surgery recovery check-in with a patient who recently had ankle surgery. The agent listens, understands responses, detects emotional tone, and replies empathetically â€” all running on **CPU-only with low latency**.

The system is built on the **LiveKit Realtime AI framework**, supporting streaming ASR, LLM conversation orchestration, and neural text-to-speech.

A **demo video is included in the submission** to illustrate the live interaction.

---

## ğŸ¬ Conversation Scenario

During the follow-up call, the agent:

1ï¸âƒ£ Introduces the purpose of the call
2ï¸âƒ£ Asks how the patient is feeling
3ï¸âƒ£ Requests a pain score (1â€“10)
4ï¸âƒ£ Guides the patient through three recovery exercises

* Ankle Mobility Stretch
* Toe Tapping
* Calf Raises
  and offers up to **1-minute pause time**
  5ï¸âƒ£ Closes the conversation politely

The tone remains:

âœ” calm
âœ” empathetic
âœ” supportive

---

## ğŸ§  System Pipeline

```
Microphone Input
 â†’ Voice Activity Detection
 â†’ Streaming Speech-to-Text
 â†’ LLM Conversation Logic
 â†’ Text-to-Speech
 â†’ Audio Output
```

### Additional Behavior (Built-In)

âœ” **Language Identification**
âœ” **Speaker Diarization**

> These are handled **natively by the streaming STT provider**,
> ensuring only English input is accepted and the primary patient speaker is detected.

### Emotion Awareness

The system additionally includes **emotion recognition** to support empathy tuning:

```
onnx-community/wav2vec2-base-Speech_Emotion_Recognition-ONNX
```

(All processing runs on **CPU**)

---

## ğŸ§© Technology Stack

| Component         | Tool                   |
|-------------------|------------------------|
| Realtime Engine   | LiveKit Agents         |
| Streaming ASR     | Deepgram via LiveKit   |
| LLM & TTS         | OpenAI via LiveKit plugin |
| Emotion Detection | ONNX Runtime           |
| Execution         | CPU only               |

---

## ğŸ“ Project Structure

```
code/
 â”œâ”€â”€ main.py              # Core agent worker
 â”œâ”€â”€ voice_agent.py       # Conversation logic
 â”œâ”€â”€ emotion_model.py     # Emotion recognition
 â”œâ”€â”€ constants.py         # Config / environment
 â””â”€â”€ ...
requirements.txt
build.sh
.env   (user-provided)
```

---

# â–¶ï¸ Running the Agent

The project is designed to run with **one script**.

### 1ï¸âƒ£ Create a `.env` file in the project root

Add your keys:

```
OPENAI_API_KEY=your_key_here
DEEPGRAM_API_KEY=your_key_here
```

These are required for:

âœ” streaming transcription
âœ” conversation response generation
âœ” TTS playback

---

### 2ï¸âƒ£ Make the script executable

```bash
chmod +x build.sh
```

### 3ï¸âƒ£ Run the agent

```bash
./build.sh
```

The script will:

âœ” install dependencies
âœ” download required models
âœ” launch the realtime agent console

No GPU is required â€” everything runs on CPU.

---

## ğŸ“¹ Demo Video

A demo video is included showing:

ğŸ™ real-time patient interaction
ğŸ§  natural conversation flow
â¤ï¸ emotion-aware agent behavior
ğŸ low latency performance

---

## ğŸ Latency Optimization

The system uses:

* streaming ASR
* non-blocking pipeline
* parallel emotion inference
* CPU-optimized ONNX runtime
* VAD to skip silence

Typical expected performance:

| Stage              | Latency   |
| ------------------ | --------- |
| Speech recognition | 100â€“300ms |
| LLM response       | < 1s      |
| TTS start          | < 300ms   |

---

## ğŸ§ª Signal Processing Rationale

| Module               | Source              | Purpose                         |
| -------------------- | ------------------- | ------------------------------- |
| Language Detection   | STT Provider        | Ensures English-only pipeline   |
| Speaker Diarization  | STT Provider        | Handles multi-speaker scenarios |
| Emotion Detection    | ONNX Model          | Supports empathetic tone        |
| VAD & Noise Handling | LiveKit Audio Stack | Improves accuracy & latency     |

> No custom diarization or language-ID model is required â€”
> **these are natively provided by the STT engine.**

---

## ğŸ”’ Safety Notes

âœ” No medical diagnosis is provided
âœ” Neutral & safe language
âœ” No PHI stored

---

## âš ï¸ Disclaimer

This project is a **technical demonstration only**
It is **not a certified clinical product**
It must **not be used for medical decision-making**

---

## ğŸ™ Acknowledgements

* LiveKit Realtime AI
* OpenAI Realtime Models
* Deepgram Streaming ASR
* ONNX Community Speech Emotion Model

---
